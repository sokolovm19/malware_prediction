# Malware prediction

This repository contains the scripts for a set of experiments that compare LGBM with Auto AI with data from [Kaggle](https://www.kaggle.com/c/microsoft-malware-prediction/data) on Microsoft Malware Prediction.

For these experiments we only used the `train.csv` file, since the `test.csv` contains only unlabelled data. We downloaded `train.csv` and renamed it `kaggle_train.csv`.

## Experiments

### Feature evaluation

With these experiments we evaluated how the LGBM classifier performs with some features removed. The goal is to reduce the complexity of the model without impacting its accuracy.

#### A: LGBM(114) - used all features

#### B: LGBM(84) - used LGBM feature extraction

In this experiment we used LGBM feature extraction to remove the features that have less than 3% of importance on the dataset. We kept 84 features.

#### C: LGBM(41) - used RF feature extraction.

In this experiment we used RF feature extraction to remove the features that have less than 3% of importance on the dataset. We kept 41 features.

### Comparison with Auto AI

With these experiments we compared LGBM with the following Auto AI: [IBM Watson Studio](https://www.ibm.com/cloud/watson-studio/autoai), [auto-sklearn](https://www.automl.org/automl/auto-sklearn/), [hyperopt-sklearn](https://hyperopt.github.io/hyperopt-sklearn/), and [TPOT](http://automl.info/tpot/). IBM Watson Studio produced the best results; the free version limits the dataset to 100,000 instances. Therefore, we evaluated LGBM with 100,000 instances, as well ([LGBM(100,000)](./LGBM(100,000))).