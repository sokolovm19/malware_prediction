# B: LGBM(84) - used LGBM feature extraction

In this experiment we used LGBM feature extraction to remove the features that have less than 3% of importance on the dataset. We kept 84 features.

## Steps

1. Preprocess data, using `Preprocessed data.ipynb`.

   Replace `https://www.kaggle.com/c/microsoft-malware-prediction/data` with `../kaggle_train.csv`.

2. Feature selection, using `LGBM features.ipynb`.

   Use `../kaggle_train.csv`.

3. Split the data into **training** and **testing** sets, using `Split train test (84).ipynb`.

   Use 80% of the data for training and 20% for testing.

4. Split the **training** data into five folds, using `data to 5 files(84).ipynb`.

5. Train LGBM on each of the five folds (`LGBM1(84).ipynb`, ..., `LGBM5(84).ipynb`), evaluate it on **testing** data, and output the predictions to `Prediction1.csv`, ..., `Prediction5.csv`.

6. Combine the predictions into one file, `majority.csv`, using the `majority.sh` script.

7. Generate the evaluation metrics, using `Voting result(84).ipynb`.
